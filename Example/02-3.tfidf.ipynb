{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "# **TF-IDF**\n",
    "Term Frequency-Inverse Document Frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "## **1 영문 데이터 전처리**\n",
    "트럼프 취임사 연설문\n",
    "1. Stemming\n",
    "1. StopWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('../data/trump.txt', 'r')\n",
    "texts = f.read()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chief',\n",
       " 'justice',\n",
       " 'roberts',\n",
       " 'president',\n",
       " 'carter',\n",
       " 'president',\n",
       " 'clinton',\n",
       " 'president',\n",
       " 'bush',\n",
       " 'president']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = texts.lower()\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "re_capt = RegexpTokenizer(r'[a-z]\\w+')\n",
    "token   = re_capt.tokenize(texts)\n",
    "token[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords_eng = stopwords.words('english')\n",
    "stopwords_eng[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chief justice roberts president carter president clinton president bush president obama fellow americans people world thank citizens america joined great national effort rebuild country restore promise people together determine course america world many many years come face challenges confront hardships get job done every four years gather steps carry orderly peaceful transfer power grateful president obama first lady michelle obama gracious aid throughout transition magnificent thank today cere'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = [txt    for txt in token   \n",
    "                if txt not in stopwords_eng]\n",
    "document = ''\n",
    "for txt in texts:\n",
    "    document += txt + ' '\n",
    "document[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "## **2 tf idf**\n",
    "연설문내 단어들의 빈도를 재조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip3 install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip3 install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x455 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 455 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vec   = TfidfVectorizer()\n",
    "transformed = tfidf_vec.fit_transform(raw_documents = [document])\n",
    "transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "transformed = np.array(transformed.todense())\n",
    "\n",
    "index_value   = {i[1]:i[0] for i in tfidf_vec.vocabulary_.items()}\n",
    "fully_indexed = {index_value[column]:value  for row in transformed  \n",
    "                                            for (column,value) in enumerate(row)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "america     0.423714\n",
       "american    0.233042\n",
       "people      0.211857\n",
       "country     0.190671\n",
       "nation      0.190671\n",
       "one         0.169485\n",
       "every       0.148300\n",
       "great       0.127114\n",
       "never       0.127114\n",
       "new         0.127114\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "tfidf = pd.Series(fully_indexed).sort_values(ascending=False)\n",
    "tfidf[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06355703979105537"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf['obama']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
