{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "# **Token의 개념**\n",
    "\n",
    "<br></br>\n",
    "## **1 Token**\n",
    "어휘분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip3 install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"힘든 월요일, 아침.\n",
    "힘든 직장인 분들에게. 월요일 식혜를 제공합니다\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize\n",
    "sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "text = word_tokenize(text)\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "## **2 Token 의 빈도분석**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from nltk import FreqDist\n",
    "dict(FreqDist(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f         = open('./data/베를린선언.txt', 'r')\n",
    "texts_org = f.read()\n",
    "f.close()\n",
    "\n",
    "texts_token = word_tokenize(texts_org)\n",
    "FreqDist(texts_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_token_dict = dict(FreqDist(texts_token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ! pip3 install pandas\n",
    "import pandas as pd\n",
    "texts_token_series = pd.Series(texts_token_dict)\n",
    "texts_token_series.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "## **3 Re 를 사용한 Regex 정규식**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Park 010-1234-1234 Kim 010-8888-9999 \n",
    "Lee 010-2123-1299 한남충 010-222-9999 메갈녀 010-555-2345\"\"\"\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "re_capt = RegexpTokenizer(r'\\d+')\n",
    "re_capt.tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "re_capt = RegexpTokenizer(r'[A-z]\\w+')\n",
    "re_capt.tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "re_capt = RegexpTokenizer(r'[가-힣]\\w+')\n",
    "re_capt.tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한글과 영문 함께 이름만 추출기 [A-z가-힣]\n",
    "# 아이디어 1 : 숫자가 아닌 내용만 추출한다\n",
    "# 아이디어 2 : 한글과 영어만 추출한다"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
